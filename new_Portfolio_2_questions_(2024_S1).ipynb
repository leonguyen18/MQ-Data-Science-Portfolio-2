{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Z88FfJc9lA_T",
      "metadata": {
        "id": "Z88FfJc9lA_T"
      },
      "source": [
        "## Analysis of an E-commerce Dataset Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hoq0NwA9lA_V",
      "metadata": {
        "id": "hoq0NwA9lA_V"
      },
      "source": [
        "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "48c24d4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fd3NU_lA_W",
      "metadata": {
        "id": "f9fd3NU_lA_W"
      },
      "source": [
        "### Import Cleaned E-commerce Dataset\n",
        "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "PJrb2gtAlA_W",
      "metadata": {
        "id": "PJrb2gtAlA_W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the data:  2685\n"
          ]
        }
      ],
      "source": [
        "# Load the data file and display the DataFrame:\n",
        "import pandas as pd\n",
        "df = pd.read_csv('cleaned_ecommerce_dataset.csv')\n",
        "print(\"Length of the data: \", len(df))\n",
        "\n",
        "# Set display width\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "9df79a6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary of numerical data:\n",
            "\n",
            "        rating  helpfulness  item_price\n",
            "count  2685.00      2685.00     2685.00\n",
            "mean      3.71         3.91       83.09\n",
            "std       1.35         0.29       42.23\n",
            "min       1.00         3.00       12.00\n",
            "25%       3.00         4.00       49.00\n",
            "50%       4.00         4.00       73.65\n",
            "75%       5.00         4.00      129.82\n",
            "max       5.00         4.00      149.00\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Summary of categorical data:\n",
            "\n",
            "        userId gender                review                  item category  item_id  user_city\n",
            "count     2685   2685                  2685                  2685     2685     2685       2685\n",
            "unique     267      2                  2675                    82        9       82         40\n",
            "top       6408      M  Being John Malkovich  AOL (America Online)   Movies        0         27\n",
            "freq        33   1407                     3                    93     1190       93        167\n"
          ]
        }
      ],
      "source": [
        "df_summary = df.copy()\n",
        "\n",
        "# Convert 'userId', 'item_id', 'user_city' to object data type\n",
        "df_summary['userId'] = df_summary['userId'].astype('object')\n",
        "df_summary['item_id'] = df_summary['item_id'].astype('object')\n",
        "df_summary['user_city'] = df_summary['user_city'].astype('object')\n",
        "\n",
        "# Summary of numerical data\n",
        "numerical_columns = ['rating', 'helpfulness', 'item_price']\n",
        "numerical_summary = df_summary[numerical_columns].describe().round(2)\n",
        "print(\"\\nSummary of numerical data:\\n\")\n",
        "print(numerical_summary)\n",
        "\n",
        "print ('------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Summary of categorical data\n",
        "categorical_columns = ['userId', 'gender', 'review', 'item', 'category', 'item_id', 'user_city']\n",
        "categorical_summary = df_summary[categorical_columns].describe(include=['O'])\n",
        "print(\"\\nSummary of categorical data:\\n\")\n",
        "print(categorical_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqbuU6rglA_X",
      "metadata": {
        "id": "aqbuU6rglA_X"
      },
      "source": [
        "### Explore the Dataset\n",
        "\n",
        "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
        "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
        "\n",
        "  Hints: To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
        "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ correlated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5675059a",
      "metadata": {},
      "source": [
        "#### 1.1. Brief information about the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "W3PImHiElA_X",
      "metadata": {
        "id": "W3PImHiElA_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current DataFrame:  \n",
            "    userId  timestamp                                           review                                item  rating  helpfulness gender               category  item_id  item_price  user_city\n",
            "0    4081      71900                                Not always McCrap                          McDonald's     4.0          3.0      M  Restaurants & Gourmet       41       30.74          4\n",
            "1    4081      72000  I dropped the chalupa even before he told me to                           Taco Bell     1.0          4.0      M  Restaurants & Gourmet       74      108.30          4\n",
            "2    4081      72000                     The Wonderful World of Wendy                             Wendy's     5.0          4.0      M  Restaurants & Gourmet       84       69.00          4\n",
            "3    4081     100399                             They actually did it  South Park: Bigger, Longer & Uncut     5.0          3.0      M                 Movies       68      143.11          4\n",
            "4    4081     100399                             Hey! Gimme some pie!                        American Pie     3.0          3.0      M                 Movies        6      117.89          4\n",
            "---------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2685 entries, 0 to 2684\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   userId       2685 non-null   int64  \n",
            " 1   timestamp    2685 non-null   int64  \n",
            " 2   review       2685 non-null   object \n",
            " 3   item         2685 non-null   object \n",
            " 4   rating       2685 non-null   float64\n",
            " 5   helpfulness  2685 non-null   float64\n",
            " 6   gender       2685 non-null   object \n",
            " 7   category     2685 non-null   object \n",
            " 8   item_id      2685 non-null   int64  \n",
            " 9   item_price   2685 non-null   float64\n",
            " 10  user_city    2685 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(4)\n",
            "memory usage: 230.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print ('The current DataFrame: ','\\n', df.head(5))\n",
        "print ('---------------------------------------------------')\n",
        "print (df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46b32377",
      "metadata": {},
      "source": [
        "#### 1.2. The correlations between helpfulness/gender/category/review and rating"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2911d1de",
      "metadata": {},
      "source": [
        "##### Convert categorical variables to numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "c26af291",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current DataFrame after encoding:  \n",
            "    userId  timestamp                                           review                                item  rating  helpfulness gender               category  item_id  item_price  user_city  gender_code  category_code  review_code\n",
            "0    4081      71900                                Not always McCrap                          McDonald's     4.0          3.0      M  Restaurants & Gourmet       41       30.74          4          1.0            8.0       1618.0\n",
            "1    4081      72000  I dropped the chalupa even before he told me to                           Taco Bell     1.0          4.0      M  Restaurants & Gourmet       74      108.30          4          1.0            8.0       1125.0\n",
            "2    4081      72000                     The Wonderful World of Wendy                             Wendy's     5.0          4.0      M  Restaurants & Gourmet       84       69.00          4          1.0            8.0       2185.0\n",
            "3    4081     100399                             They actually did it  South Park: Bigger, Longer & Uncut     5.0          3.0      M                 Movies       68      143.11          4          1.0            5.0       2243.0\n",
            "4    4081     100399                             Hey! Gimme some pie!                        American Pie     3.0          3.0      M                 Movies        6      117.89          4          1.0            5.0       1033.0\n",
            "The current DataFrame after encoding:  \n",
            "       userId  timestamp                                             review                                       item  rating  helpfulness gender                  category  item_id  item_price  user_city  gender_code  category_code  review_code\n",
            "2485   10434     122200               Ebay - The Gift That Keeps On Giving                                       eBay     5.0          4.0      F  Online Stores & Services       88      149.00         12          0.0            6.0        687.0\n",
            "2486   10468      52800  American Beauty: &quot;Never underestimate the...                            American Beauty     5.0          4.0      F                    Movies        5       59.00          1          0.0            5.0        282.0\n",
            "2487   10468      52900  Kevin Smith + Catholic Church: You know it'll ...                                      Dogma     4.0          4.0      F                    Movies       22       87.59          1          0.0            5.0       1311.0\n",
            "2488   10468      60100  Gladiator, or &quot;macho, macho man&quot; Rom...                                  Gladiator     4.0          4.0      F                    Movies       30       65.17          1          0.0            5.0        887.0\n",
            "2489   10468      70800  &quot;The Perfect Storm&quot;--yeah, that just...                              Perfect Storm     5.0          4.0      F                    Movies       54      129.87          1          0.0            5.0         39.0\n",
            "...      ...        ...                                                ...                                        ...     ...          ...    ...                       ...      ...         ...        ...          ...            ...          ...\n",
            "2680    2445      22000                                       Great movie!      Austin Powers: The Spy Who Shagged Me     5.0          3.0      M                    Movies        9      111.00          5          1.0            5.0        968.0\n",
            "2681    2445      30700                                         Good food!                         Outback Steakhouse     5.0          3.0      M     Restaurants & Gourmet       50       25.00          5          1.0            8.0        920.0\n",
            "2682    2445      61500                                       Great movie!                                 Fight Club     5.0          3.0      M                    Movies       26       97.53          5          1.0            5.0        968.0\n",
            "2683    2445     100500                                      Awesome Game.  The Sims 2: Open for Business for Windows     5.0          4.0      M                     Games       79       27.00          5          1.0            1.0        372.0\n",
            "2684    2445     101400                                     Great Service.                                     PayPal     5.0          3.0      M          Personal Finance       52       38.00          5          1.0            7.0        959.0\n",
            "\n",
            "[200 rows x 14 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert categorical variables to numerical\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ord_enc = OrdinalEncoder()\n",
        "df[['gender_code', 'category_code', 'review_code']] = ord_enc.fit_transform(df[['gender', 'category', 'review']])\n",
        "print ('The current DataFrame after encoding: ','\\n', df.head(5))\n",
        "print ('The current DataFrame after encoding: ','\\n', df.tail(200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "c8bbccd7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  gender  gender_code\n",
            "0      F          0.0\n",
            "1      M          1.0\n"
          ]
        }
      ],
      "source": [
        "# Display the original and encoded 'Gender'\n",
        "df[[\"gender\", \"gender_code\"]].head(5)\n",
        "# Each unique category along with its corresponding code\n",
        "gender_code_info = df[['gender', 'gender_code']].drop_duplicates()\n",
        "gender_code_info = gender_code_info.sort_values('gender_code').reset_index(drop=True)\n",
        "print(gender_code_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "af2f1acd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   category  category_code\n",
            "0                     Books            0.0\n",
            "1                     Games            1.0\n",
            "2           Hotels & Travel            2.0\n",
            "3             Kids & Family            3.0\n",
            "4                     Media            4.0\n",
            "5                    Movies            5.0\n",
            "6  Online Stores & Services            6.0\n",
            "7          Personal Finance            7.0\n",
            "8     Restaurants & Gourmet            8.0\n"
          ]
        }
      ],
      "source": [
        "# Display the original and encoded 'Category'\n",
        "df[[\"category\", \"category_code\"]].head(5)\n",
        "# Each unique category along with its corresponding code\n",
        "category_code_info = df[['category', 'category_code']].drop_duplicates()\n",
        "category_code_info = category_code_info.sort_values('category_code').reset_index(drop=True)\n",
        "print(category_code_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016364cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We are working with a dataset related to customer reviews, so we might try to group categories based on the type of product or service they represent.   \n",
        "\n",
        "For example, we could group the categories as follows:\n",
        "Entertainment: Book, Games, Movies, Media\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "da00a0bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   category  category_code  group_code\n",
            "0                    Movies            5.0           0\n",
            "1                     Media            4.0           0\n",
            "2                     Games            1.0           0\n",
            "3                     Books            0.0           0\n",
            "4           Hotels & Travel            2.0           1\n",
            "5     Restaurants & Gourmet            8.0           2\n",
            "6             Kids & Family            3.0           3\n",
            "7  Online Stores & Services            6.0           4\n",
            "8          Personal Finance            7.0           5\n"
          ]
        }
      ],
      "source": [
        "# Define the encoding for the new groups\n",
        "group_codes = {\n",
        "    \"Books\": 0,  # Entertainment\n",
        "    \"Games\": 0,  # Entertainment\n",
        "    \"Movies\": 0,  # Entertainment\n",
        "    \"Media\": 0,  # Entertainment\n",
        "    \"Hotels & Travel\": 1,  # Travel\n",
        "    \"Restaurants & Gourmet\": 2,  # Restaurant\n",
        "    \"Kids & Family\": 3,  # Kids & Family\n",
        "    \"Online Stores & Services\": 4,  # Online Services\n",
        "    \"Personal Finance\": 5  # Finance\n",
        "}\n",
        "\n",
        "# Create a new column for the group codes\n",
        "df['group_code'] = df['category'].map(group_codes)\n",
        "\n",
        "# Display each unique category, category_code, and group_code\n",
        "group_code_info = df[['category', 'category_code', 'group_code']].drop_duplicates()\n",
        "group_code_info = group_code_info.sort_values('group_code').reset_index(drop=True)\n",
        "print(group_code_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "22275519",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 review  review_code\n",
            "0      &quot;What We Do In This Life Echoes In Etern...          0.0\n",
            "1                                A TWELVE GAUGE WHOPPER          1.0\n",
            "2      AYANKJOINSTHERAFforFROMHERETOETERNITY&spends3...          2.0\n",
            "3                  Can I please get some good service?           3.0\n",
            "4                       Crouching Kitty, Hidden Lizard           4.0\n",
            "...                                                 ...          ...\n",
            "2670                             where to not live/live       2670.0\n",
            "2671                      why marry a multi-millionare?       2671.0\n",
            "2672                       wow is this hard to get into       2672.0\n",
            "2673            x.com - - The world's future in banking       2673.0\n",
            "2674                                    you can have it       2674.0\n",
            "\n",
            "[2675 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display the original and encoded 'Review'\n",
        "df[[\"review\", \"review_code\"]].head(5)\n",
        "# Each unique category along with its corresponding code\n",
        "review_code_info = df[['review', 'review_code']].drop_duplicates()\n",
        "review_code_info = review_code_info.sort_values('review_code').reset_index(drop=True)\n",
        "print(review_code_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d304815",
      "metadata": {},
      "source": [
        "##### Calculate the correlations between variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "70d71e05",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>helpfulness</th>\n",
              "      <th>gender_code</th>\n",
              "      <th>category_code</th>\n",
              "      <th>review_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007523</td>\n",
              "      <td>-0.034337</td>\n",
              "      <td>-0.163158</td>\n",
              "      <td>-0.036118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>helpfulness</th>\n",
              "      <td>-0.007523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.075947</td>\n",
              "      <td>-0.013408</td>\n",
              "      <td>-0.028259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_code</th>\n",
              "      <td>-0.034337</td>\n",
              "      <td>0.075947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022549</td>\n",
              "      <td>-0.037884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category_code</th>\n",
              "      <td>-0.163158</td>\n",
              "      <td>-0.013408</td>\n",
              "      <td>0.022549</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_code</th>\n",
              "      <td>-0.036118</td>\n",
              "      <td>-0.028259</td>\n",
              "      <td>-0.037884</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 rating  helpfulness  gender_code  category_code  review_code\n",
              "rating         1.000000    -0.007523    -0.034337      -0.163158    -0.036118\n",
              "helpfulness   -0.007523     1.000000     0.075947      -0.013408    -0.028259\n",
              "gender_code   -0.034337     0.075947     1.000000       0.022549    -0.037884\n",
              "category_code -0.163158    -0.013408     0.022549       1.000000     0.001970\n",
              "review_code   -0.036118    -0.028259    -0.037884       0.001970     1.000000"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select the columns: 'rating', 'helpfulness' and encoded variables of 'gender_code', 'category_code', 'review_code'\n",
        "selected_columns = df[['rating', 'helpfulness', 'gender_code', 'category_code', 'review_code']]\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = selected_columns.corr()\n",
        "correlation_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "ee4afb23",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation between helpfulness and rating\n",
            "             helpfulness    rating\n",
            "helpfulness     1.000000 -0.007523\n",
            "rating         -0.007523  1.000000\n",
            "---------------------------------------------------\n",
            "Correlation between gender and rating\n",
            "             gender_code    rating\n",
            "gender_code     1.000000 -0.034337\n",
            "rating         -0.034337  1.000000\n",
            "---------------------------------------------------\n",
            "Correlation between category and rating\n",
            "               category_code    rating\n",
            "category_code       1.000000 -0.163158\n",
            "rating             -0.163158  1.000000\n",
            "---------------------------------------------------\n",
            "Correlation between review and rating\n",
            "            group_code    rating\n",
            "group_code    1.000000 -0.135336\n",
            "rating       -0.135336  1.000000\n",
            "---------------------------------------------------\n",
            "Correlation between review and rating\n",
            "             review_code    rating\n",
            "review_code     1.000000 -0.036118\n",
            "rating         -0.036118  1.000000\n",
            "---------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# The correlations between helpfulness/gender/category/review and rating\n",
        "\n",
        "# Correlation between helpfulness and rating\n",
        "print ('Correlation between helpfulness and rating')\n",
        "print (df[['helpfulness', 'rating']].corr())\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "# Correlation between gender and rating\n",
        "print ('Correlation between gender and rating')\n",
        "print (df[['gender_code', 'rating']].corr())\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "# Correlation between category and rating\n",
        "print ('Correlation between category and rating')\n",
        "print (df[['category_code', 'rating']].corr())\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "\n",
        "# Correlation between GROUPED CATEGORY and rating\n",
        "print ('Correlation between review and rating')\n",
        "print (df[['group_code', 'rating']].corr())\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "# Correlation between review and rating\n",
        "print ('Correlation between review and rating')\n",
        "print (df[['review_code', 'rating']].corr())\n",
        "print ('---------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9926ed6d",
      "metadata": {},
      "source": [
        "#### 1.3. Please provide necessary explanations/analysis on the correlations, and figure out which are the most and least correlated features regarding rating. Try to discuss how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aee2036",
      "metadata": {},
      "outputs": [],
      "source": [
        "train, test = train_test_split(iris, test_size=0.2, random_state=142)\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) #20% for test\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4myP5igslA_Y",
      "metadata": {
        "id": "4myP5igslA_Y"
      },
      "source": [
        "### Split Training and Testing Data\n",
        "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
        "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
        "    * Case 1: training data containing 10% of the entire data;\n",
        "    * Case 2: training data containing 90% of the entire data.\n",
        "* Print the shape of training and testing sets in the two cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "JIDMig9blA_Y",
      "metadata": {
        "id": "JIDMig9blA_Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Case 1:\n",
            "Training set shape: (268, 14) (268,)\n",
            "Testing set shape: (2417, 14) (2417,)\n",
            "---------------------------------------------------\n",
            "Case 2:\n",
            "Training set shape: (2416, 14) (2416,)\n",
            "Testing set shape: (269, 14) (269,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the features and target variable\n",
        "X = df.drop('rating', axis=1)\n",
        "y = df['rating']\n",
        "\n",
        "# Case 1: Training data contains 10% of the entire data\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.9, random_state=142)\n",
        "\n",
        "# Case 2: Training data contains 90% of the entire data\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.1, random_state=142)\n",
        "\n",
        "# Print the shape of the training and testing sets\n",
        "print(\"Case 1:\")\n",
        "print(\"Training set shape:\", X_train_1.shape, y_train_1.shape)\n",
        "print(\"Testing set shape:\", X_test_1.shape, y_test_1.shape)\n",
        "\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "print(\"Case 2:\")\n",
        "print(\"Training set shape:\", X_train_2.shape, y_train_2.shape)\n",
        "print(\"Testing set shape:\", X_test_2.shape, y_test_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "2bdb6380",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and Testing set for Case 1\n",
            "(268, 15)\n",
            "(2417, 15)\n",
            "---------------------------------------------------\n",
            "Training and Testing set for Case 2\n",
            "(2416, 15)\n",
            "(269, 15)\n"
          ]
        }
      ],
      "source": [
        "### Practical Workshop Method\n",
        "## Split the data into training and testing sets\n",
        "# Case 1: 10% of the data is used for training and 90% for testing\n",
        "train_1, test_1 = train_test_split(df, test_size=0.9, random_state=142)\n",
        "print ('Training and Testing set for Case 1')\n",
        "print(train_1.shape)\n",
        "print(test_1.shape)\n",
        "print ('---------------------------------------------------')\n",
        "\n",
        "# Case 2: 90% of the data is used for training and 10% for testing\n",
        "train_2, test_2 = train_test_split(df, test_size=0.1, random_state=142)\n",
        "print ('Training and Testing set for Case 2')\n",
        "print(train_2.shape)\n",
        "print(test_2.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DjSsgT0BlA_Y",
      "metadata": {
        "id": "DjSsgT0BlA_Y"
      },
      "source": [
        "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
        "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
        "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features from helpfulness/gender/category/review regarding rating, respectively.\n",
        "* Train four linear regression models by following the conditions:\n",
        "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
        "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
        "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
        "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
        "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DASzPUATlA_Z",
      "metadata": {
        "id": "DASzPUATlA_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "KATSn7hYlA_Z",
      "metadata": {
        "id": "KATSn7hYlA_Z"
      },
      "source": [
        "### Evaluate Models\n",
        "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
        "* Print the results of the four models regarding the two metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fU8GPS9lA_Z",
      "metadata": {
        "id": "4fU8GPS9lA_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Y9jx-eY6lA_a",
      "metadata": {
        "id": "Y9jx-eY6lA_a"
      },
      "source": [
        "### Visualize, Compare and Analyze the Results\n",
        "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
        "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3TNAIGDilA_a",
      "metadata": {
        "id": "3TNAIGDilA_a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f9ee01ac",
      "metadata": {
        "id": "f9ee01ac"
      },
      "source": [
        "### Data Science Ethics\n",
        "*Please read the following examples [Click here to read the example_1.](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) [Click here to read the example_2.](https://viborc.com/ethics-and-ethical-data-visualization-a-complete-guide/)\n",
        "\n",
        "*Then view the picture ![My Image](figure_portfolio2.png \"This is my image\")\n",
        "Please compose an analysis of 100-200 words that evaluates potential ethical concerns associated with the infographic, detailing the reasons behind these issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f30e9b",
      "metadata": {
        "id": "44f30e9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0511889d",
      "metadata": {
        "id": "0511889d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
